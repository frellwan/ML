---
title: "STAT 578 - Fall 2019 - Assignment 6"
author: "Frederick (Eric) Ellwanger - fre2"
date: "December 7, 2019"
output:
  pdf_document: default
  html_document: 
    toc: yes
urlcolor: cyan
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
options(digits=3)
options(scipen = 999)
```

## Exercise 1  
**Using plot(Ht ~ Pos, data= $\cdots$ ), display box plots of height by position. Is there a relationship between height and position? (Such a relationship might cause substantial posterior correlations between regression coeffcients if both height and position are used as explanatory variables.)**
```{r}
illinibb <- read.csv("illinimensbb.csv")
plot(Ht ~ Pos, data = illinibb)
```  
**There appears to be a relationship between height and position, the taller players play center (with what appears to be no overlap with the other positions), while the shorter players tend to play guard (although there is some overlap with he forward position)**  


## Exercise 2  
**Let $y_i$ be the number of field goals made by player $i$ out of $n_i$ attempts (i = 1, $\ldots$, 15). Consider the following logistic regression (with implicit intercept) on player position and height:**  

\[y_i|p_i \hspace{2mm}  \sim \hspace{2mm} indep \hspace{2mm}Bin(n_i, p_i) \]  
\[logit(p_i) = \beta_{Pos(i)} + \beta_{Ht} H_i \]  

**where:**  
**$Pos(i)$ = player $i$ position (C, F, G)**  
**$H_i$ = player $i$ height after centering and scaling to sample standard dev. 0.5**  

**Consider the prior:**  
$\beta_C, \beta_F, \beta_G \sim iid t1(0, 10^2)$  $\hspace{10mm}$      $\beta_{Ht} \sim t1(0, 2.5^2)$  
**(2)(a) List an appropriate JAGS model. Include nodes for the vector of binomial probabilities pi and a vector yrep of replicate responses.**  

```
model {
   for (i in 1:length(illinibb)) {
      fgm[i] ~ dbin(prob[i], fga[i])
      logit(prob[i]) <- betapos[pos[i]] + betaht*htscaled[i]
      
      yrep[i] ~ dbin(prob[i], fga[i])
   }

   for (j in 1:max(pos)) {
      betapos[j] ~ dt(0, 0.01, 1)
   }

   betaht ~ dt(0, 0.16, 1)
}
```  

Now run your model using rjags. Make sure to use multiple chains with overdispersed starting points, check convergence, and monitor the regression coeffcients, probabilities, and replicate responses (after convergence) long enough to obtain effective sample sizes of at least 4000 for each regression coeffcient.

```{r message=FALSE, warning=FALSE}
d1 <- list(fgm = illinibb$FGM,
           fga = illinibb$FGA,
           pos = unclass(illinibb$Pos),
           htscaled = as.vector(scale(illinibb$Ht, scale=2*sd(illinibb$Ht))))

inits1 <- list(list(betapos=c(10,10,10), betaht=10),
               list(betapos=c(10,10,-10), betaht=-10),
               list(betapos=c(10,-10,10), betaht=-10),
               list(betapos=c(10,-10,-10), betaht=10))

library(rjags)

m1 <- jags.model("ilinnibb.bug", d1, inits1, n.chains=4, n.adapt=1000)

update(m1, 1000) # burn-in

x1 <- coda.samples(m1, c("betapos","betaht"), n.iter=2000)

#Check convergence
gelman.diag(x1, autoburnin=FALSE)

#Add additional variable - prob and yrep
x1 <- coda.samples(m1, c("betapos","betaht","prob","yrep"), n.iter=8000)

#Check for effective sample size > 4000
effectiveSize(x1[,1:4])

```  

**(2)(b) Display the coda summary of the results for the monitored regression coeffcients.**  
```{r}
summary(x1[,1:4])
```  

**(2)(c) With your posterior samples, display scatterplots of (i) $\beta_C$ versus $\beta_{Ht}$, (ii) $\beta_F$ versus $\beta_{Ht}$, and (iii) $\beta_G$ versus $\beta_{Ht}$. Do you see (posterior) correlations?**  

```{r}
betaposs = as.matrix(x1)[, paste("betapos[",1:3,"]", sep="")]
betahts = as.matrix(x1)[, paste("betaht", sep="")]

#betaC ~ betaHt
plot(betahts ~ betaposs[,1])

#betaF ~ betaHt
plot(betahts ~ betaposs[,2])

#betaG ~ betaHt
plot(betahts ~ betaposs[,3])
```  

**(2)(d) Consider the modeled probability that Ayo Dosunmu (No. 11) successfully makes an attempted field goal. Plot the (approximate) posterior density of this probability.**  
```{r}
#probs = as.matrix(x1)[, paste("prob[",1:nrow(illinibb),"]", sep="")]
#plot(probs[,4])
densplot(x1[,"prob[4]"], main = "Density of P(Ayo Dosunmu makes FGA)")

```


**(2)(e) Approximate the posterior probability that $\beta_F$ > $\beta_G$ (i.e., that forwards have a higher probability of successfully making an attempted field goal than guards, after adjusting for height). Also, approximate the Bayes factor favoring $\beta_F$ > $\beta_G$ versus $\beta_F$ < $\beta_G$. (Note that, by symmetry, $\beta_F$ > $\beta_G$ and $\beta_F$ < $\beta_G$ have equal prior probability.) What can you say about the data evidence that $\beta_F$ > $\beta_G$?
```{r}
probs = as.matrix(x1)[, paste("prob[",1:nrow(illinibb),"]", sep="")]
mean(probs[,2] > probs[,3])
```

```{r}
#Since PR_prior_h1 = PR_prior_h2 we divide by 1
(BF = (mean(probs[,2] > probs[,3])/mean(probs[,2] < probs[,3]))/1)
```  
**The Bayes Factor is approximately `r BF`. This is at a anectodal level supporting H1 on the Bayes Factor scale, suggesting there isn't much evidence to support that $\beta_F > \beta_G$**


**(2)(f) Use the chi-square discrepancy to compute an approximate posterior predictive p-value. Does it indicate any evidence of problems (such as overdispersion)?**  
```{r}
yreps <- as.matrix(x1)[, paste("yrep[",1:nrow(illinibb),"]", sep="")]

Tchi <- numeric(nrow(yreps))
Tchirep <- numeric(nrow(yreps))

for(s in 1:nrow(yreps)){
  Tchi[s] <- sum((illinibb$FGM - illinibb$FGA*probs[s,])^2/(illinibb$FGA*probs[s,]*(1-probs[s,])))
  Tchirep[s] <- sum((yreps[s,] - illinibb$FGA*probs[s,])^2/(illinibb$FGA*probs[s,]*(1-probs[s,])))
}

mean(Tchirep >= Tchi)
```


**(2)(g) Now consider expanding the model to allow for overdispersion.**   

**(2)(g)(i) List an appropriately modied JAGS model. Then run it using rjags, with all of the usual steps.**  
```
model {
   for (i in 1:length(pos)) {
      fgm[i] ~ dbin(prob[i], fga[i])
      logit(prob[i]) <- betapos[pos[i]] + betaht*htscaled[i] + epsilon[i] 
      epsilon[i] ~ dnorm(0,1/sigmaepsilon^2)
      
      yrep[i] ~ dbin(prob[i], fga[i])
   }

   for (j in 1:max(pos)) {
      betapos[j] ~ dt(0, 0.01, 1)
   }

   betaht ~ dt(0, 0.16, 1)
   
   sigmaepsilon ~ dunif(0,10)
}
```  
```{r message=FALSE, warning=FALSE}
d2 <- list(fgm = illinibb$FGM,
           fga = illinibb$FGA,
           pos = unclass(illinibb$Pos),
           htscaled = as.vector(scale(illinibb$Ht, scale=2*sd(illinibb$Ht))))

inits2 <- list(list(betapos=c(10,10,10), betaht=10, sigmaepsilon = 0.01),
               list(betapos=c(10,10,-10), betaht=-10, sigmaepsilon = 9),
               list(betapos=c(10,-10,10), betaht=-10, sigmaepsilon = 0.01),
               list(betapos=c(10,-10,-10), betaht=10, sigmaepsilon = 9))

m2 <- jags.model("ilinnibb2.bug", d2, inits2, n.chains=4, n.adapt=1000)

update(m2, 1000) # burn-in

x2 <- coda.samples(m2, c("betapos","betaht"), n.iter=8000)

#Check convergence
gelman.diag(x2, autoburnin=FALSE)

#Add additional variable - prob, yrep, and sigmaepsilon
x2 <- coda.samples(m2, c("betapos","betaht","prob","yrep", "sigmaepsilon"), n.iter=60000)

#Check for effective sample size > 4000
effectiveSize(x2[,1:4])

```  

**(2)(g)(ii)Plot the (approximate) posterior density of $\sigma_\epsilon$".**
```{r}
densplot(x2[,"sigmaepsilon"], main = expression(paste("Density of ", sigma[epsilon])))
```

**(2)(g)(iii) Repeat part (e) under this expanded model. Does your conclusion change? **

```{r}
probs2 = as.matrix(x2)[, paste("prob[",1:nrow(illinibb),"]", sep="")]
mean(probs2[,2] > probs2[,3])

#Since PR_prior_h1 = PR_prior_h2 we divide by 1
(BF = (mean(probs2[,2] > probs2[,3])/mean(probs2[,2] < probs2[,3]))/1)
```  
**This is very similar to (e) above. This does not change the conclusion**


