# Cloud Computing Applications
Cloud Computing Applications is a comprehensive 17-week course that delves into the revolutionary world of cloud computing and Big Data. Throughout the course, students explore a wide array of technologies shaping modern cloud computing stacks. Starting with foundational concepts, economic principles, and Big Data fundamentals, the curriculum progresses to cover software-defined architectures and the organizational strategies of major cloud service providers like Amazon, Google, and Microsoft. The course highlights the rising popularity of serverless computing, emphasizing its cost-effectiveness and ease of deployment. Students also gain insights into Big Data programming using Apache Hadoop and Apache Spark, alongside discussions on various cloud storage options including object storage, block storage, and archival solutions. Distributed computing challenges and solutions, such as distributed key-value stores and in-memory databases like Memcached and Redis, are also explored. The curriculum further extends to NewSQL and NoSQL databases, focusing on technologies like HBase for scalable, low-latency operations. Additionally, the course covers advanced topics such as distributed messaging systems like Kafka, essential for connecting Big Data and streaming applications. Analyzing large volumes of static and streaming data, the course underscores how cloud-based data analytics is transforming information usage across industries. It introduces enterprise-level analytics applications offered by major cloud providers and explores graph processing, graph databases, and machine learning within cloud environments. The curriculum also includes Fast Data systems like Apache Storm for real-time data streaming, and discusses streaming architectures such as Lambda and Kappa. Finally, the course concludes with an exploration of virtualization and container technologies, providing in-depth lectures on Docker, ECS, Kubernetes, and Infrastructure as Code, essential for deploying cloud-based services effectively.

### MP0
Count the number of times words are used in a document

### MP2
Create a AWS Lambda function to add a graph network to a dynamo DB table calculating the distances between cities. Create another lambda function to take the source and destination and return the shortest distance between the two cities.

### MP3
Use AWS EKS to create a kubernetes cluster that distinguishes between a free and premium tier (for resource usage) to run a pytorch classification model for classification.

### MP4
Use Hadoop MapReduce for several different tasks

### MP5
Use PySpark for several of the MapReduce tasks in MP4

### MP6 
Use Apache Storm to build a topology that finds the top N words in a given corpus with several different bolts.

### MP7
Usa Apache HBase to add and retrieve information.

### MP8
Use PySpark SQL to interact with a database

### MP9
Use Tablaue to answer question about the flight database

### MP10
Use PySpark ML to train a random forest classifier
